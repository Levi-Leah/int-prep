= Terraform Questions

== What is Terraform, and what is its primary purpose?

Terraform is an open-source Infrastructure as Code (IaC) tool created by HashiCorp that enables you to define, provision, and manage infrastructure using declarative configuration files.

*Primary purpose*: Automate infrastructure provisioning across multiple cloud providers and services through code, enabling version control, reproducibility, and collaboration. Instead of manually clicking through cloud consoles or writing imperative scripts, you declare desired infrastructure state in configuration files, and Terraform handles the execution.

*Key characteristics*:

* *Declarative* - you specify what infrastructure you want (desired state), not how to create it (Terraform figures out steps).
* *Cloud-agnostic* - works with AWS, Azure, GCP, Kubernetes, and 1000+ providers.
* *State management* - tracks infrastructure state enabling updates and drift detection.
* *Plan before apply* - preview changes before execution reducing risks.

*From security perspective*: Terraform enables infrastructure security at scale through consistent configuration enforcement, security controls defined as code and reviewed, audit trail via version control showing who changed what and when, automated compliance checking against security policies, and reproducible secure infrastructure across environments. Security teams can review infrastructure changes in pull requests before deployment, implement policy-as-code (Sentinel, OPA) blocking insecure configurations, and maintain golden modules with security best practices baked in.

Terraform is foundational to modern cloud security because it treats infrastructure configuration as software - versioned, tested, reviewed, and deployed through controlled pipelines rather than ad-hoc manual changes.

== What makes Terraform a cloud-agnostic tool?

Terraform achieves cloud-agnosticism through its *provider architecture* - a plugin system allowing Terraform to interact with different platforms via standardized APIs.

*How it works*:

* *Provider plugins* - separate binaries for each platform (AWS, Azure, GCP, Kubernetes, etc.) downloaded automatically when running `terraform init`.
* *Common HCL syntax* - same configuration language regardless of provider enabling consistent experience across clouds.
* *State abstraction* - Terraform's state management works identically across all providers.

*Benefits for organizations*:

* *Avoid vendor lock-in* - can migrate between clouds or use multiple clouds without rewriting entire infrastructure.
* *Consistent workflow* - same `terraform plan`, `terraform apply` commands regardless of target platform.
* *Unified tooling* - single tool for all infrastructure (cloud, SaaS, on-premises).
* *Skills transferability* - team learns Terraform once, applies everywhere.

*Example multi-cloud configuration*:

[,hcl]
----
# AWS resources
provider "aws" {
  region = "us-east-1"
}

resource "aws_s3_bucket" "data" {
  bucket = "myapp-data"
}

# Azure resources
provider "azurerm" {
  features {}
}

resource "azurerm_storage_account" "backup" {
  name                = "myappbackup"
  resource_group_name = azurerm_resource_group.main.name
}

# GCP resources
provider "google" {
  project = "my-project"
  region  = "us-central1"
}

resource "google_storage_bucket" "archive" {
  name     = "myapp-archive"
  location = "US"
}
----

*Security implications*:

* *Multi-cloud strategy* requires consistent security across providers (encryption, access controls, monitoring), Terraform enables defining security standards once applied everywhere, but cloud-specific security features require provider-specific configuration.
* CAUTION: Cloud-agnostic doesn't mean cloud-independent - each provider has unique security capabilities, Terraform abstracts provisioning but can't abstract away cloud differences, security teams must understand each cloud's security model.
* *Best practice*: Use Terraform's cloud-agnosticism for consistent provisioning workflow and security baseline but leverage cloud-native security features where appropriate through provider-specific resources.

== How does Terraform differ from other IaC tools like CloudFormation or Ansible?

*Terraform vs CloudFormation*:

* *Cloud scope* - Terraform: multi-cloud and multi-platform; CloudFormation: AWS-only.
* *Language* - Terraform: HCL (human-readable); CloudFormation: JSON/YAML (verbose).
* *State management* - Terraform: explicit state file tracking resources; CloudFormation: implicit (AWS manages stacks).
* *Modularity* - Terraform: modules highly reusable across projects; CloudFormation: nested stacks (more complex).
* *Community* - Terraform: 1000+ providers, large community; CloudFormation: AWS resources only.
* *Import* - Terraform: can import existing resources; CloudFormation: limited import capability.
* *From security perspective*: Terraform provides better multi-cloud security management, CloudFormation tightly integrated with AWS security services (native IAM, KMS).

*Terraform vs Ansible*:

* *Paradigm* - Terraform: declarative (what you want); Ansible: primarily imperative (how to do it).
* *Purpose* - Terraform: infrastructure provisioning; Ansible: configuration management and orchestration.
* *State* - Terraform: stateful (tracks resources); Ansible: stateless (unless using Tower/AWX).
* *Idempotency* - Terraform: inherent (runs create desired state); Ansible: modules should be idempotent but must be designed carefully.
* *Mutable vs Immutable* - Terraform: encourages immutable infrastructure (replace, not modify); Ansible: typically modifies in-place (mutable).
* *Agent* - Terraform: agentless (API-driven); Ansible: agentless (SSH/WinRM).

*Comparison table*:

|===
| Feature | Terraform | CloudFormation | Ansible

| Scope
| Multi-cloud
| AWS only
| Multi-cloud

| Approach
| Declarative
| Declarative
| Imperative/Declarative

| State
| Explicit state file
| Managed by AWS
| Stateless

| Use case
| Infrastructure provisioning
| AWS infrastructure
| Configuration + provisioning

| Language
| HCL
| JSON/YAML
| YAML

| Modularity
| Excellent
| Good (nested stacks)
| Good (roles)

| Learning curve
| Moderate
| Moderate
| Easy to start
|===

*When to use what*:

* *Terraform*: Multi-cloud infrastructure, immutable infrastructure patterns, team needs version-controlled infrastructure, strong state management required.
* *CloudFormation*: AWS-only shop, deep AWS integration needed, comfortable with AWS ecosystem.
* *Ansible*: Configuration management (OS setup, app deployment), existing infrastructure (mutable), orchestration workflows, simple automation tasks.

*In practice, combined*: Terraform provisions infrastructure (VMs, networks, databases), Ansible configures instances (install software, configure services).

*Security considerations*:

* *Terraform* - security controls defined declaratively, policy-as-code enforcement (Sentinel, OPA), state file security critical (contains sensitive data).
* *CloudFormation* - tight AWS IAM integration, AWS-native security features, CloudFormation service roles for deployment.
* *Ansible* - Ansible Vault for secrets, SSH key management important, playbook security review needed.

Many organizations use Terraform for infrastructure provisioning and Ansible for configuration management - complementary tools serving different purposes.

== What is the core Terraform workflow?

The core Terraform workflow consists of four stages: *Write → Plan → Apply → Repeat*.

*1. Write* - define infrastructure as code:

[,hcl]
----
# main.tf
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"

  tags = {
    Name = "WebServer"
  }
}
----

*2. Initialize* (`terraform init`): Download provider plugins (AWS, Azure, etc.), initialize backend (state storage), download referenced modules, prepare working directory. Run once per directory or when adding new providers/modules.

*3. Plan* (`terraform plan`): Compare desired state (configuration files) with current state (state file), determine what actions needed (create, update, delete), show execution plan for review, no changes made yet (dry-run). *Critical security gate* - review plan before applying, verify no unintended changes, check for security implications.

*4. Apply* (`terraform apply`): Execute the plan creating/modifying/deleting resources, update state file with current infrastructure, output results and any output values. Changes infrastructure to match configuration.

*5. Destroy* (`terraform destroy`) when needed: Remove all managed infrastructure, clean up resources, update state file. Only when decommissioning.

*Complete workflow example*:

[,bash]
----
# 1. Write configuration (main.tf created)

# 2. Initialize
terraform init
# Output: Initializing provider plugins...

# 3. Plan and review
terraform plan -out=tfplan
# Output: Plan: 1 to add, 0 to change, 0 to destroy

# Review plan carefully!
# Check for unexpected changes
# Verify security configurations

# 4. Apply
terraform apply tfplan
# Infrastructure created

# 5. Make changes to config, repeat plan/apply
# Edit main.tf...
terraform plan
terraform apply

# 6. When done, destroy
terraform destroy
----

*Security workflow enhancements*:

* *Pre-commit* - lint configuration (tflint), scan for security issues (tfsec, checkov), detect secrets (git-secrets).
* *Plan stage* - automated security scanning of plan, policy validation (Sentinel, OPA), peer review of plan output.
* *Apply stage* - approval gate for production, deployment only from CI/CD (not local), state file backup before apply.
* *Post-apply* - verify deployment, compliance scanning, drift detection scheduled.

*Best practices*: Always run `plan` before `apply`, save plan output for approval workflow (`terraform plan -out=tfplan`), never skip plan in automation, implement approval gates for production, comprehensive logging and audit trail, and version control all configuration files.

The workflow is iterative - write, plan, review, apply, repeat - with security checkpoints at each stage ensuring safe infrastructure changes.

== What are the key Terraform commands, and what do they do?

*Core commands*:

* *`terraform init`* - Initialize working directory: downloads provider plugins, initializes backend, downloads modules. Run first in new directory or when adding providers/modules. Idempotent (safe to run multiple times).
* *`terraform plan`* - Preview changes: compares config with state, shows what will be created/modified/deleted, saves plan to file with `-out`. Always run before apply. No infrastructure changes.
* *`terraform apply`* - Apply changes: executes plan creating/updating/deleting resources, updates state file. Can auto-approve with `-auto-approve` (use cautiously). Modifies infrastructure.
* *`terraform destroy`* - Destroy infrastructure: removes all managed resources, updates state file. Requires confirmation. Use with extreme caution.

*State management*:

* *`terraform state list`* - List resources in state: shows all managed resources. Useful for inventory.
* *`terraform state show <resource>`* - Show resource details: displays attributes of specific resource from state.
* *`terraform state mv`* - Move resource in state: renames resource in state without destroying/recreating. Useful for refactoring.
* *`terraform state rm`* - Remove resource from state: stops Terraform managing resource (doesn't delete resource). Use when manually deleting or transferring management.

*Validation and formatting*:

* *`terraform validate`* - Validate configuration: checks syntax and internal consistency. Doesn't check provider APIs. Quick syntax check.
* *`terraform fmt`* - Format configuration: standardizes formatting (indentation, spacing). Run before committing.

*Import and refresh*:

* *`terraform import`* - Import existing resource: add existing infrastructure to Terraform management. Requires resource address and ID.
* *`terraform refresh`* - Update state from real infrastructure: sync state with actual resources. (Deprecated - plan now does this automatically).

*Workspace management*:

* *`terraform workspace list/new/select`* - Manage workspaces: separate state files for different environments.

*Advanced*:

* *`terraform taint <resource>`* - Mark resource for recreation: forces resource destruction and recreation on next apply. (Deprecated - use `terraform apply -replace=<resource>`).
* *`terraform output`* - Show outputs: display output values from state.
* *`terraform graph`* - Generate dependency graph: visualize resource dependencies (DOT format).
* *`terraform show`* - Inspect state or plan: human-readable output of state or saved plan.

*Security-relevant commands*:

* *`terraform plan -out=tfplan`* - Save plan for approval: separates planning from application enabling review gates.
* *`terraform show -json tfplan`* - JSON plan output: machine-readable format for automated security scanning.
* *`terraform state pull`* - Download remote state: for backup or inspection (carefully - contains sensitive data).
* *`terraform providers lock`* - Lock provider versions: creates dependency lock file preventing supply chain attacks.

*Example secure workflow*:

[,bash]
----
# Format and validate
terraform fmt -recursive
terraform validate

# Security scanning (external tools)
tfsec .
checkov -d .

# Plan with approval
terraform plan -out=tfplan

# Review plan
terraform show tfplan

# Apply specific plan (approved)
terraform apply tfplan

# Verify outputs
terraform output

# Check state
terraform state list
----

*Best practices*: Never use `-auto-approve` in production without review, always save and review plans before apply, use `terraform fmt` before commits, run `terraform validate` in CI/CD, implement policy-as-code scanning plan output, lock provider versions for reproducibility, regularly backup state files, and audit terraform commands in production (comprehensive logging).

Understanding these commands is essential for safe Terraform operations - misuse can cause production outages or security issues.

== What is the basic structure of a Terraform configuration file?

Terraform configurations written in HashiCorp Configuration Language (HCL) with `.tf` extension. Basic structure includes several key components:

*Provider block* - specifies which provider (AWS, Azure, etc.):

[,hcl]
----
provider "aws" {
  region = "us-east-1"
}
----

*Resource block* - defines infrastructure components:

[,hcl]
----
resource "aws_instance" "web_server" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"

  tags = {
    Name = "WebServer"
  }
}
----

*Data source block* - query existing infrastructure:

[,hcl]
----
data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"]  # Canonical

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }
}
----

*Variable block* - define inputs:

[,hcl]
----
variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"
}
----

*Output block* - expose values:

[,hcl]
----
output "instance_ip" {
  description = "Public IP of web server"
  value       = aws_instance.web_server.public_ip
}
----

*Locals block* - define local values:

[,hcl]
----
locals {
  common_tags = {
    Environment = "production"
    ManagedBy   = "terraform"
  }
}
----

*Module block* - call reusable modules:

[,hcl]
----
module "vpc" {
  source = "./modules/vpc"

  cidr_block = "10.0.0.0/16"
  environment = "prod"
}
----

*Complete example* with security best practices:

[,hcl]
----
# versions.tf - specify required versions
terraform {
  required_version = ">= 1.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }

  # Remote state with encryption
  backend "s3" {
    bucket         = "terraform-state-bucket"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}

# providers.tf
provider "aws" {
  region = var.aws_region

  default_tags {
    tags = local.common_tags
  }
}

# variables.tf
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"
}

# locals.tf
locals {
  common_tags = {
    Environment = var.environment
    Project     = "web-app"
    ManagedBy   = "terraform"
    Owner       = "platform-team"
  }
}

# main.tf
data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"]

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }
}

resource "aws_instance" "web" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.instance_type

  # Security: no public IP, private subnet
  associate_public_ip_address = false
  subnet_id                   = module.vpc.private_subnet_ids[0]

  # Security: instance profile with minimal permissions
  iam_instance_profile = aws_iam_instance_profile.web.name

  # Security: encrypted EBS
  root_block_device {
    encrypted = true
  }

  # Security: security group limiting access
  vpc_security_group_ids = [aws_security_group.web.id]

  tags = merge(local.common_tags, {
    Name = "web-server"
  })
}

# outputs.tf
output "instance_id" {
  description = "EC2 instance ID"
  value       = aws_instance.web.id
}

output "private_ip" {
  description = "Private IP address"
  value       = aws_instance.web.private_ip
  sensitive   = false  # Not sensitive (private IP)
}
----

*File organization best practices*:

* *Single directory structure*: `main.tf` - primary resources, `variables.tf` - input variables, `outputs.tf` - output values, `providers.tf` - provider config, `versions.tf` - version constraints, `locals.tf` - local values, `data.tf` - data sources.
* *Or resource-focused*: `ec2.tf`, `rds.tf`, `vpc.tf` - grouped by resource type.

*Security considerations*:

* *Never commit secrets* - use variables from environment or secret managers.
* *Sensitive outputs* - mark with `sensitive = true` to prevent logging.
* *Version constraints* - pin provider versions preventing unexpected changes.
* *State backend* - always use encrypted remote backend.
* *Resource naming* - consistent naming conventions for audit trails.
* *Tags* - comprehensive tagging for security, compliance, cost tracking.

== What are Terraform providers, and why are they important?

Providers are Terraform plugins enabling interaction with APIs of cloud platforms, SaaS providers, and other services. They translate HCL configuration into API calls creating/managing resources.

*What providers do*:

* *API abstraction* - provide unified interface to disparate APIs, handle authentication and API specifics, manage API rate limiting and retries.
* *Resource types* - define available resource types (aws_instance, azure_vm), specify resource arguments and attributes.
* *Data sources* - enable querying existing infrastructure.
* *State mapping* - map Terraform resources to API resources for state tracking.

*Provider examples*:

* *Cloud providers*: AWS (aws), Azure (azurerm), Google Cloud (google), DigitalOcean (digitalocean).
* *Kubernetes*: kubernetes, helm.
* *SaaS*: Datadog (datadog), PagerDuty (pagerduty), GitHub (github).
* *Infrastructure*: vSphere (vsphere), Docker (docker).
* *Security*: Vault (vault), Auth0 (auth0).

*Provider configuration*:

[,hcl]
----
# AWS provider
provider "aws" {
  region = "us-east-1"

  # Security: use IAM role, not hardcoded keys
  # Credentials from environment, instance profile, or AWS config

  default_tags {
    tags = {
      ManagedBy = "terraform"
    }
  }
}

# Azure provider
provider "azurerm" {
  features {}  # Required

  subscription_id = var.azure_subscription_id
}

# Multiple provider instances (different regions)
provider "aws" {
  alias  = "us_west"
  region = "us-west-2"
}

resource "aws_instance" "west" {
  provider = aws.us_west  # Use specific provider

  ami           = "ami-xyz"
  instance_type = "t3.micro"
}
----

*Provider versions*:

[,hcl]
----
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"  # Registry source
      version = "~> 4.0"  # Version constraint
    }
  }
}
----

*Why providers are important*:

* *Extensibility* - 1000+ providers support virtually any service, community can create custom providers.
* *Abstraction* - consistent workflow across different platforms, same HCL syntax regardless of provider.
* *Updates* - providers updated independently of Terraform core, bug fixes and new features without Terraform upgrade.
* *Security and compliance* - providers implement platform-specific security, handle authentication properly, support compliance features.

*Security considerations for providers*:

*Authentication* - *Never hardcode credentials* in provider blocks, use environment variables, instance profiles/managed identities, credential files.

*Example secure auth*:

[,hcl]
----
provider "aws" {
  region = "us-east-1"
  # Credentials automatically from:
  # 1. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
  # 2. Shared credentials file (~/.aws/credentials)
  # 3. IAM instance profile (EC2)
  # 4. IAM role (ECS task, Lambda)
}
----

*Provider versioning* - *Lock provider versions* preventing supply chain attacks, use version constraints (~> for minor updates, = for exact version).

*Example*:

[,hcl]
----
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "= 4.67.0"  # Exact version for security
    }
  }
}
----

*Dependency lock file* - `terraform init` creates `.terraform.lock.hcl` locking exact provider versions and checksums, commit to version control for team consistency, prevents malicious provider substitution.

*Provider trust* - Providers are executable binaries (security risk), use official providers from HashiCorp registry (verified), audit custom/community providers before use, and review provider source code if highly sensitive.

*Best practices*: Explicitly define provider versions, commit `.terraform.lock.hcl` to version control, use official verified providers when possible, implement least privilege for provider credentials, never commit provider credentials to Git, use separate providers for different environments (dev/prod), regularly update providers for security patches, and audit provider permissions and access.

Providers are the interface between Terraform and your infrastructure - securing them is critical for overall security posture.

== What are Terraform resources?

Resources are the fundamental building blocks in Terraform representing infrastructure components like VMs, networks, databases, or any manageable entity.

*Resource syntax*:

[,hcl]
----
resource "resource_type" "resource_name" {
  # Configuration arguments
  argument1 = "value1"
  argument2 = "value2"
}
----

*Example resources*:

[,hcl]
----
# AWS EC2 instance
resource "aws_instance" "web" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t3.micro"

  tags = {
    Name = "WebServer"
  }
}

# AWS S3 bucket
resource "aws_s3_bucket" "data" {
  bucket = "my-data-bucket"
}

# Azure virtual machine
resource "azurerm_linux_virtual_machine" "main" {
  name                = "myvm"
  resource_group_name = azurerm_resource_group.main.name
  location            = azurerm_resource_group.main.location
  size                = "Standard_B2s"

  admin_username = "adminuser"
}
----

*Resource characteristics*:

* *Unique identifier* - resource type + name uniquely identifies resource in configuration.
* *State tracking* - Terraform tracks each resource in state file.
* *Lifecycle* - resources created, updated, or destroyed based on configuration changes.
* *Dependencies* - implicit or explicit relationships with other resources.
* *Attributes* - computed values after creation (IDs, IPs, etc.).

*Resource lifecycle*:

[,hcl]
----
resource "aws_instance" "example" {
  ami           = "ami-xyz"
  instance_type = "t3.micro"

  lifecycle {
    create_before_destroy = true  # Create new before deleting old
    prevent_destroy       = true  # Prevent accidental deletion
    ignore_changes        = [tags]  # Ignore specific changes
  }
}
----

*Resource meta-arguments*:

* *`depends_on`* - explicit dependencies.
* *`count`* - create multiple identical resources.
* *`for_each`* - create resources from map/set.
* *`provider`* - specify which provider to use.
* *`lifecycle`* - control resource lifecycle.
* *`provisioner`* - execute scripts during creation/destruction (discouraged).

*Resource references*: Resources can reference each other creating dependencies:

[,hcl]
----
resource "aws_instance" "web" {
  ami             = data.aws_ami.ubuntu.id
  instance_type   = "t3.micro"
  subnet_id       = aws_subnet.main.id  # Reference subnet
  security_groups = [aws_security_group.web.id]  # Reference SG
}

# Can access attributes
output "instance_ip" {
  value = aws_instance.web.public_ip  # Access computed attribute
}
----

*Security-focused resource examples*:

[,hcl]
----
# Encrypted S3 bucket
resource "aws_s3_bucket" "secure" {
  bucket = "secure-data-bucket"
}

resource "aws_s3_bucket_server_side_encryption_configuration" "secure" {
  bucket = aws_s3_bucket.secure.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.s3.arn
    }
  }
}

resource "aws_s3_bucket_public_access_block" "secure" {
  bucket = aws_s3_bucket.secure.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Security group with least privilege
resource "aws_security_group" "web" {
  name        = "web-sg"
  description = "Web server security group"
  vpc_id      = aws_vpc.main.id

  # Only allow HTTPS
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # Minimal outbound
  egress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "web-sg"
  }
}

# IAM role with least privilege
resource "aws_iam_role" "ec2_role" {
  name = "ec2-app-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
      Action = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy" "ec2_policy" {
  name = "ec2-policy"
  role = aws_iam_role.ec2_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Action = [
        "s3:GetObject"  # Only read from specific bucket
      ]
      Resource = "${aws_s3_bucket.data.arn}/*"
    }]
  })
}
----

*Resource naming conventions*: Use descriptive names (not "resource1"), follow consistent pattern (resource_type_purpose), lowercase with underscores. *Example*: `aws_instance.web_server`, `aws_security_group.database_sg`, `azurerm_storage_account.app_storage`.

*Best practices*:

* *Least privilege* - grant minimum necessary permissions.
* *Encryption* - enable encryption by default on all resources supporting it.
* *Access control* - restrict access through security groups, IAM policies, network ACLs.
* *Tagging* - comprehensive tags for security, compliance, cost tracking.
* *Immutable infrastructure* - prefer replacing resources over modifying (create_before_destroy).
* *Validation* - use lifecycle rules preventing accidental destructive changes.

Resources are the actual infrastructure Terraform manages - properly securing them is essential for overall infrastructure security.

== What are Terraform modules, and why are modules used?

Modules are containers for multiple resources that are used together, enabling reusable, composable infrastructure components. A module is simply a directory containing `.tf` files.

*Why use modules*:

* *Reusability* - write once, use many times across projects.
* *Consistency* - standardized configurations ensuring best practices.
* *Abstraction* - hide complexity behind simple interface.
* *Organization* - logical grouping of related resources.
* *Testing* - modules can be tested independently.
* *Security enforcement* - embed security controls in modules.

*Module structure*:

[,bash]
----
modules/
  secure-vpc/
    main.tf        # Resources
    variables.tf   # Inputs
    outputs.tf     # Outputs
    README.md      # Documentation
----

*Example secure VPC module*:

[,hcl]
----
# modules/secure-vpc/variables.tf
variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
}

variable "environment" {
  description = "Environment name"
  type        = string
}

# modules/secure-vpc/main.tf
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name        = "${var.environment}-vpc"
    Environment = var.environment
  }
}

resource "aws_flow_log" "main" {
  vpc_id          = aws_vpc.main.id
  traffic_type    = "ALL"
  iam_role_arn    = aws_iam_role.flow_logs.arn
  log_destination = aws_cloudwatch_log_group.flow_logs.arn
}

resource "aws_default_security_group" "default" {
  vpc_id = aws_vpc.main.id

  # Lock down default SG (best practice)
  # No ingress/egress rules = deny all

  tags = {
    Name = "${var.environment}-default-sg-locked"
  }
}

# modules/secure-vpc/outputs.tf
output "vpc_id" {
  description = "VPC ID"
  value       = aws_vpc.main.id
}

output "vpc_cidr" {
  description = "VPC CIDR block"
  value       = aws_vpc.main.cidr_block
}
----

*Using the module*:

[,hcl]
----
# main.tf
module "production_vpc" {
  source = "./modules/secure-vpc"

  vpc_cidr    = "10.0.0.0/16"
  environment = "production"
}

module "staging_vpc" {
  source = "./modules/secure-vpc"

  vpc_cidr    = "10.1.0.0/16"
  environment = "staging"
}

# Reference module outputs
output "prod_vpc_id" {
  value = module.production_vpc.vpc_id
}
----

*Module sources*:

* *Local modules*: `source = "./modules/vpc"` - modules in same repo.
* *Terraform Registry*: `source = "terraform-aws-modules/vpc/aws"` - public registry.
* *GitHub*: `source = "github.com/org/repo//modules/vpc"` - Git repos.
* *Version constraints*: `source = "terraform-aws-modules/vpc/aws"` with `version = "3.14.0"`.

*Security benefits of modules*:

* *Embedded security controls* - security best practices baked into modules (encryption, access controls, logging).
* *Consistent security* - all usage inherits security configurations.
* *Centralized updates* - fix security issues once in module, update everywhere.
* *Security review* - review module once, confident in all usage.
* *Golden modules* - organization-approved secure patterns.

*Example security-focused module*:

[,hcl]
----
# modules/secure-s3-bucket/main.tf
resource "aws_s3_bucket" "this" {
  bucket = var.bucket_name
}

# Force encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "this" {
  bucket = aws_s3_bucket.this.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = var.kms_key_id
    }
  }
}

# Block public access (always)
resource "aws_s3_bucket_public_access_block" "this" {
  bucket = aws_s3_bucket.this.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Enable versioning
resource "aws_s3_bucket_versioning" "this" {
  bucket = aws_s3_bucket.this.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Logging
resource "aws_s3_bucket_logging" "this" {
  bucket = aws_s3_bucket.this.id

  target_bucket = var.logging_bucket
  target_prefix = "s3-logs/${var.bucket_name}/"
}
----

*Module best practices*:

* *Single responsibility* - module should do one thing well.
* *Well-defined interface* - clear inputs (variables) and outputs.
* *Documentation* - README explaining purpose, inputs, outputs, examples.
* *Versioning* - semantic versioning for registry modules.
* *Testing* - automated tests validating module functionality.
* *Security defaults* - secure by default, require opt-in for less secure configurations.
* *No hardcoded values* - parameterize everything that might vary.

== What is the difference between a root module and a child module?

*Root module* is the main working directory where you run Terraform commands, containing the primary `.tf` files and calling other modules. *Child modules* are external modules called by the root module, typically stored in subdirectories or external sources.

*Root module characteristics*:

* *Entry point* - where `terraform init`, `terraform apply` run.
* *Configuration* - contains provider configuration, backend configuration.
* *Orchestration* - calls child modules, passes variables, uses outputs.
* *State* - state file created in root module context.
* *Variables* - can have variables passed via CLI, environment, or .tfvars files.

*Child module characteristics*:

* *Reusable components* - designed for reuse across projects.
* *Encapsulation* - internal resources hidden, only inputs/outputs exposed.
* *No provider config* - inherits providers from root module.
* *No backend* - no separate state, resources tracked in root module state.
* *Versioning* - can have versions (especially registry modules).

*Example structure*:

[,bash]
----
project-root/  # ROOT MODULE
├── main.tf
├── variables.tf
├── outputs.tf
├── terraform.tfvars
├── modules/  # CHILD MODULES
│   ├── vpc/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   └── ec2/
│       ├── main.tf
│       ├── variables.tf
│       └── outputs.tf
└── .terraform/
----

*Root module (main.tf)*:

[,hcl]
----
terraform {
  required_version = ">= 1.0"

  backend "s3" {
    bucket = "terraform-state"
    key    = "prod/terraform.tfstate"
  }
}

provider "aws" {
  region = var.aws_region
}

# Calling child modules
module "vpc" {
  source = "./modules/vpc"

  vpc_cidr    = "10.0.0.0/16"
  environment = "production"
}

module "web_servers" {
  source = "./modules/ec2"

  vpc_id     = module.vpc.vpc_id  # Using child module output
  subnet_ids = module.vpc.private_subnet_ids
  count      = 3
}

# Root module variables
variable "aws_region" {
  default = "us-east-1"
}

# Root module outputs
output "vpc_id" {
  value = module.vpc.vpc_id
}
----

*Child module (modules/vpc/main.tf)*:

[,hcl]
----
# No provider or backend configuration (inherits from root)

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
}

variable "environment" {
  description = "Environment name"
  type        = string
}

resource "aws_vpc" "main" {
  cidr_block = var.vpc_cidr

  tags = {
    Name = "${var.environment}-vpc"
  }
}

output "vpc_id" {
  value = aws_vpc.main.id
}

output "vpc_cidr" {
  value = aws_vpc.main.cidr_block
}
----

*Key differences*:

|===
| Aspect | Root Module | Child Module

| Provider config
| Required
| Inherited

| Backend config
| Required
| Not allowed

| State file
| Creates/manages
| Resources tracked in root state

| Execution
| Direct (terraform apply)
| Called by root

| Variables
| Multiple sources
| Only from module call

| Purpose
| Orchestration
| Reusable component
|===

*Data flow*: Root module → passes variables → Child module, Child module → returns outputs → Root module, Root module → orchestrates multiple child modules.

*Security implications*:

* *Root module security* - secures backend configuration (state encryption, locking), manages provider credentials, enforces policy-as-code, and controls what modules are called.
* *Child module security* - implements security best practices internally, validates input variables, and provides secure defaults.
* *Separation of concerns* - root module handles environment-specific config, child modules contain reusable secure patterns.
* *Version control* - child modules versioned independently enabling security patches, root module pins versions for stability.

*Best practices*:

* *Root module* - minimal code (mostly module calls), environment-specific values, backend and provider configuration, orchestration logic.
* *Child modules* - generic and reusable, well-documented interface, secure by default, no environment-specific hardcoding.
* *Communication* - explicit through variables (input) and outputs (return values), child modules self-contained.

Understanding root vs. child modules is key to organizing Terraform code effectively and maintaining security boundaries.

== What is the typical file structure of a Terraform module?

A well-organized Terraform module follows a standard file structure enabling readability, maintainability, and reusability.

*Basic module structure*:

[,bash]
----
module-name/
├── main.tf          # Primary resources
├── variables.tf     # Input variables
├── outputs.tf       # Output values
├── versions.tf      # Version constraints
├── README.md        # Documentation
├── .terraform.lock.hcl  # Dependency lock
├── examples/        # Usage examples
│   └── basic/
│       ├── main.tf
│       └── variables.tf
├── tests/           # Automated tests
│   └── module_test.go
└── .gitignore       # Git ignore patterns
----

*Core files explained*:

*`main.tf`* - primary resource definitions:

[,hcl]
----
resource "aws_instance" "this" {
  ami           = var.ami_id
  instance_type = var.instance_type

  # Security: encrypted EBS
  root_block_device {
    encrypted = true
  }

  tags = merge(var.tags, {
    Name = var.name
  })
}
----

*`variables.tf`* - input variable declarations:

[,hcl]
----
variable "ami_id" {
  description = "AMI ID for EC2 instance"
  type        = string
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"

  validation {
    condition     = contains(["t3.micro", "t3.small", "t3.medium"], var.instance_type)
    error_message = "Instance type must be t3.micro, t3.small, or t3.medium"
  }
}

variable "tags" {
  description = "Tags to apply to resources"
  type        = map(string)
  default     = {}
}
----

*`outputs.tf`* - output value declarations:

[,hcl]
----
output "instance_id" {
  description = "EC2 instance ID"
  value       = aws_instance.this.id
}

output "private_ip" {
  description = "Private IP address"
  value       = aws_instance.this.private_ip
}

output "public_ip" {
  description = "Public IP address"
  value       = aws_instance.this.public_ip
  sensitive   = true  # Mark sensitive data
}
----

*`versions.tf`* - Terraform and provider version constraints:

[,hcl]
----
terraform {
  required_version = ">= 1.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ">= 4.0, < 5.0"
    }
  }
}
----

*`README.md`* - comprehensive documentation:

[,markdown]
----
# Secure EC2 Module

## Description
Creates EC2 instances with security best practices enabled:
- Encrypted EBS volumes
- Instance profile with least privilege
- Security group with minimal access
- CloudWatch monitoring enabled

## Usage
```hcl
module "web_server" {
  source = "./modules/ec2"

  ami_id        = "ami-abc123"
  instance_type = "t3.micro"
  subnet_id     = "subnet-xyz"

  tags = {
    Environment = "production"
  }

}
```

## Inputs

| Name | Description | Type | Default | Required |
|----|---------|----|------|-------|
| ami_id | AMI ID | string | n/a | yes |
| instance_type | Instance type | string | t3.micro | no |

## Outputs

| Name | Description |
|----|---------|
| instance_id | EC2 instance ID |

## Security Considerations

* EBS volumes encrypted by default
* No public IP assigned
* Runs in private subnet

----

*Larger modules* with multiple resource types:

[,bash]
----
complex-module/
├── main.tf              # Main orchestration
├── variables.tf         # All variables
├── outputs.tf           # All outputs
├── versions.tf          # Version constraints
├── ec2.tf               # EC2-specific resources
├── security-groups.tf   # Security group resources
├── iam.tf               # IAM resources
├── data.tf              # Data sources
├── locals.tf            # Local values
├── README.md            # Documentation
└── examples/
    ├── basic/
    └── advanced/
----

*Security-focused structure*:

[,bash]
----
secure-app-module/
├── main.tf              # Core resources
├── variables.tf         # Variables
├── outputs.tf           # Outputs
├── versions.tf          # Versions
├── security-groups.tf   # Network security
├── iam.tf               # Access control
├── kms.tf               # Encryption keys
├── monitoring.tf        # CloudWatch, alerts
├── compliance.tf        # Compliance resources
├── README.md            # Documentation
├── SECURITY.md          # Security documentation
└── examples/
    └── secure-deployment/
----

*`.gitignore`* for Terraform:

[,bash]
----
# .gitignore
.terraform/
*.tfstate
*.tfstate.*
.terraform.lock.hcl  # Or commit for consistency
*.tfvars  # Don't commit sensitive values
**/.terraform/*
crash.log
override.tf
override.tf.json
----

*Best practices for file organization*:

* *Separation of concerns* - each file has clear purpose.
* *Naming conventions* - descriptive file names (security-groups.tf, not sg.tf).
* *Size limits* - files shouldn't exceed 300-500 lines (split if larger).
* *Logical grouping* - related resources together.
* *README first* - always include comprehensive README.
* *Examples included* - show how to use the module.
* *Security documentation* - explain security decisions and configurations.

*Module sizing guidance*:

* *Small modules* (< 10 resources) - single main.tf is fine.
* *Medium modules* (10-50 resources) - split by resource type (ec2.tf, rds.tf, etc.).
* *Large modules* (> 50 resources) - consider breaking into sub-modules.

A well-structured module is self-documenting, easy to understand, testable, and maintainable - essential for security-critical infrastructure code that will be reviewed and audited.

== What is the Terraform state file, and why is it important?

The Terraform state file (`terraform.tfstate`) is JSON file tracking the current state of managed infrastructure, mapping Terraform configuration to real-world resources.

*What state contains*:

* *Resource mapping* - links Terraform resource IDs to cloud provider resource IDs (terraform resource `aws_instance.web` → AWS instance `i-abc123`).
* *Resource attributes* - stores all resource attributes including computed values (IPs, IDs, ARNs).
* *Metadata* - version info, backend config, resource dependencies.
* *Outputs* - cached output values.
* *Provider configuration* - references to configured providers.

*Example state snippet*:

[,json]
----
{
  "version": 4,
  "terraform_version": "1.5.0",
  "resources": [
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "web",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "attributes": {
            "id": "i-abc123def456",
            "ami": "ami-0c55b159cbfafe1f0",
            "instance_type": "t3.micro",
            "private_ip": "10.0.1.50",
            "public_ip": "54.123.45.67"
          }
        }
      ]
    }
  ]
}
----

*Why state is crucial*:

* *Resource tracking* - Terraform knows what it manages vs. other resources, can update/destroy only managed resources.
* *Performance* - avoids querying cloud APIs for every operation, state provides cached resource info.
* *Collaboration* - shared state enables team collaboration, prevents conflicts through locking.
* *Drift detection* - comparing state to reality reveals configuration drift.
* *Dependency resolution* - state tracks resource dependencies enabling proper order of operations.

*State workflow*:

----
1. terraform plan
   - Read state file
   - Query current config
   - Compare state vs config
   - Generate execution plan

2. terraform apply
   - Execute plan
   - Update state with new resource info
   - Write updated state file

3. Next plan/apply cycle repeats
----

*Security implications - STATE FILES CONTAIN SENSITIVE DATA*:

*Sensitive data in state*:

* Passwords and secrets (database passwords, API keys)
* Private keys (SSH keys, TLS certificates)
* IP addresses and network topology
* Resource IDs enabling targeted attacks
* Configuration details revealing vulnerabilities

*Example sensitive data in state*:

[,json]
----
{
  "resources": [
    {
      "type": "aws_db_instance",
      "instances": [{
        "attributes": {
          "password": "SuperSecretPassword123!",  // ⚠️ PLAINTEXT PASSWORD
          "username": "admin",
          "endpoint": "mydb.abc123.us-east-1.rds.amazonaws.com:3306"
        }
      }]
    }
  ]
}
----

*State security requirements*:

* *Never commit to Git* - `.gitignore` should include `*.tfstate`, accidental commits expose all secrets.
* *Encrypt at rest* - remote backends should encrypt state (S3 with KMS, Azure Storage with encryption).
* *Encrypt in transit* - HTTPS for remote state access.
* *Access control* - strict IAM/RBAC on state storage, only authorized users/systems access state.
* *Versioning* - enable versioning for backup/recovery (S3 versioning, Azure blob versioning).
* *Locking* - prevent concurrent modifications corrupting state.

*State file backup* - critical for disaster recovery:

[,bash]
----
# Manual backup before risky operations
terraform state pull > terraform.tfstate.backup

# S3 backend automatically versions
aws s3api list-object-versions \
  --bucket terraform-state \
  --prefix prod/terraform.tfstate
----

*Best practices*:

* *Remote state always* - never use local state in production.
* *Encryption mandatory* - state must be encrypted at rest and in transit.
* *Least privilege access* - limit who can read/write state.
* *State locking enabled* - prevent concurrent operations.
* *Regular backups* - automated state backups.
* *Audit logging* - track state access and modifications.
* *Separate states* - different state files per environment (dev/staging/prod).

State file security is non-negotiable - a compromised state file is a complete security breach exposing all infrastructure secrets and topology.

== Why is storing Terraform state remotely considered a best practice?

Remote state storage is essential for production Terraform usage, providing collaboration, security, and reliability benefits that local state cannot.

*Problems with local state*:

* *No collaboration* - only one person can work at a time, state on laptop not accessible to team.
* *No locking* - concurrent operations can corrupt state.
* *No backup* - losing laptop = losing state (disaster).
* *No encryption* - state sitting on disk potentially unencrypted.
* *No versioning* - can't recover from mistakes.
* *No audit trail* - no record of who changed what.

*Benefits of remote state*:

*1. Collaboration*:

* *Shared access* - entire team accesses same state, enables distributed team work.
* *Concurrent safety* - state locking prevents simultaneous operations.
* *Consistency* - everyone works from same source of truth.

*2. Security*:

* *Encryption at rest* - state encrypted in storage (S3 with KMS, Azure with encryption).
* *Encryption in transit* - HTTPS for state access.
* *Access control* - IAM/RBAC controls who can read/write state.
* *Audit logging* - track all state access (CloudTrail, Azure Monitor).
* *No local copies* - state never sits on developer laptops unencrypted.

*3. Reliability*:

* *Durability* - S3 11 9's durability, Azure/GCP equivalent.
* *Versioning* - automatic state versioning for rollback.
* *Backup* - built-in backup and recovery.
* *Disaster recovery* - state survives laptop failures, team member departures.

*4. CI/CD integration*:

* *Automated deployments* - CI/CD systems access remote state, no manual state management.
* *Consistent environments* - all environments use same state management pattern.

*Remote backend examples*:

*S3 backend* (most common for AWS):

[,hcl]
----
terraform {
  backend "s3" {
    bucket         = "terraform-state-prod"
    key            = "project/terraform.tfstate"
    region         = "us-east-1"

    # Security essentials
    encrypt        = true  # Encrypt state
    kms_key_id     = "arn:aws:kms:us-east-1:123456789:key/abc-123"

    # Locking
    dynamodb_table = "terraform-locks"

    # Versioning (enable on bucket)
  }
}
----

*Azure Storage backend*:

[,hcl]
----
terraform {
  backend "azurerm" {
    resource_group_name  = "terraform-state-rg"
    storage_account_name = "terraformstateprod"
    container_name       = "tfstate"
    key                  = "prod.terraform.tfstate"
  }
}
----

*Terraform Cloud backend*:

[,hcl]
----
terraform {
  backend "remote" {
    organization = "my-org"

    workspaces {
      name = "production"
    }
  }
}
----

*GCS backend* (Google Cloud Storage):

[,hcl]
----
terraform {
  backend "gcs" {
    bucket  = "terraform-state-prod"
    prefix  = "terraform/state"
  }
}
----

*Setting up secure S3 backend* (complete example):

[,bash]
----
# 1. Create S3 bucket
aws s3api create-bucket \
  --bucket terraform-state-prod \
  --region us-east-1

# 2. Enable versioning
aws s3api put-bucket-versioning \
  --bucket terraform-state-prod \
  --versioning-configuration Status=Enabled

# 3. Enable encryption
aws s3api put-bucket-encryption \
  --bucket terraform-state-prod \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "aws:kms",
        "KMSMasterKeyID": "arn:aws:kms:..."
      },
      "BucketKeyEnabled": true
    }]
  }'

# 4. Block public access
aws s3api put-public-access-block \
  --bucket terraform-state-prod \
  --public-access-block-configuration \
    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"

# 5. Enable logging
aws s3api put-bucket-logging \
  --bucket terraform-state-prod \
  --bucket-logging-status file://logging.json

# 6. Create DynamoDB table for locking
aws dynamodb create-table \
  --table-name terraform-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST
----

*IAM policy for state access* (least privilege):

[,json]
----
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket"
      ],
      "Resource": "arn:aws:s3:::terraform-state-prod"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject"
      ],
      "Resource": "arn:aws:s3:::terraform-state-prod/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:DescribeTable",
        "dynamodb:GetItem",
        "dynamodb:PutItem",
        "dynamodb:DeleteItem"
      ],
      "Resource": "arn:aws:dynamodb:*:*:table/terraform-locks"
    }
  ]
}
----

*Migration from local to remote* state:

[,bash]
----
# 1. Configure backend in Terraform config
# (add backend block to versions.tf)

# 2. Initialize (migrates state)
terraform init -migrate-state

# 3. Verify migration
terraform state list

# 4. Delete local state
rm terraform.tfstate*
----

*Best practices*: Use remote state for all non-trivial projects, enable encryption always, implement state locking, enable versioning for rollback, restrict access via IAM/RBAC, enable audit logging, separate state per environment, and regular state backups (though versioning provides this).

Remote state is foundational to secure, collaborative Terraform usage - it's not optional for production workloads.

== What are remote backends in Terraform?

Remote backends are storage locations for Terraform state files that are accessed over a network, providing collaboration, security, and reliability features.

*Backend types*:

*Standard backends* (state storage only):

* *S3* - AWS S3 bucket, most popular for AWS users.
* *Azure Storage* - Azure Blob Storage.
* *GCS* - Google Cloud Storage.
* *HTTP* - generic HTTP endpoint.
* *Consul* - HashiCorp Consul key-value store.
* *etcd* - etcd key-value store.

*Enhanced backends* (state + operations):

* *Terraform Cloud* - HashiCorp's SaaS offering with UI, RBAC, policies.
* *Terraform Enterprise* - self-hosted Terraform Cloud.

*Backend configuration syntax*:

[,hcl]
----
terraform {
  backend "backend_type" {
    # Configuration arguments
  }
}
----

*Common backends detailed*:

*S3 Backend*:

[,hcl]
----
terraform {
  backend "s3" {
    # Required
    bucket = "my-terraform-state"
    key    = "path/to/terraform.tfstate"
    region = "us-east-1"

    # Security
    encrypt        = true
    kms_key_id     = "arn:aws:kms:..."

    # Locking
    dynamodb_table = "terraform-locks"

    # Authentication
    # Uses AWS credentials chain (env vars, instance profile, etc.)
  }
}
----

*Azure Storage Backend*:

[,hcl]
----
terraform {
  backend "azurerm" {
    resource_group_name  = "tfstate-rg"
    storage_account_name = "tfstate"
    container_name       = "tfstate"
    key                  = "terraform.tfstate"

    # Uses Azure authentication (az cli, service principal, managed identity)
  }
}
----

*GCS Backend*:

[,hcl]
----
terraform {
  backend "gcs" {
    bucket  = "tf-state-bucket"
    prefix  = "terraform/state"

    # Uses GCP authentication (gcloud, service account)
  }
}
----

*Terraform Cloud Backend*:

[,hcl]
----
terraform {
  cloud {
    organization = "my-org"

    workspaces {
      name = "production"
    }
  }
}
----

*Backend features comparison*:

|===
| Feature | S3 | Azure Storage | GCS | Terraform Cloud

| State storage
| ✓
| ✓
| ✓
| ✓

| State locking
| ✓ (DynamoDB)
| ✓ (built-in)
| ✓ (built-in)
| ✓

| Encryption
| ✓ (KMS)
| ✓
| ✓ (CMEK)
| ✓

| Versioning
| ✓ (S3 versioning)
| ✓ (blob versioning)
| ✓ (object versioning)
| ✓

| UI
| ✗
| ✗
| ✗
| ✓

| RBAC
| IAM
| Azure RBAC
| IAM
| ✓

| Policy as Code
| ✗
| ✗
| ✗
| ✓ (Sentinel)

| Cost
| $$ (S3 + DynamoDB)
| $
| $$
| Free tier, then $$$
|===

*Backend initialization*:

[,bash]
----
# Initialize backend
terraform init

# Migrate from local to remote
terraform init -migrate-state

# Reconfigure backend (change config)
terraform init -reconfigure

# View current backend config
terraform version
----

*Backend configuration methods*:

*Method 1: In configuration* (recommended):

[,hcl]
----
terraform {
  backend "s3" {
    bucket = "terraform-state"
    key    = "prod/terraform.tfstate"
  }
}
----

*Method 2: Partial configuration + CLI*:

[,hcl]
----
# versions.tf
terraform {
  backend "s3" {}  # Partial config
}
----

[,bash]
----
# Provide rest via CLI
terraform init \
  -backend-config="bucket=terraform-state" \
  -backend-config="key=prod/terraform.tfstate"
----

*Method 3: Backend config file*:

[,hcl]
----
# backend.hcl
bucket = "terraform-state"
key    = "prod/terraform.tfstate"
region = "us-east-1"
encrypt = true
----

[,bash]
----
terraform init -backend-config=backend.hcl
----

*Security considerations for backends*:

* *Access control*: Strict IAM/RBAC permissions, separate read vs. write permissions, CI/CD service accounts with minimal permissions, human users with appropriate access.
* *Encryption*: Always enable encryption at rest, use customer-managed keys when possible (KMS, CMEK), encryption in transit (HTTPS).
* *Audit logging*: Enable access logs (CloudTrail, Azure Monitor, Cloud Audit Logs), monitor for unauthorized access, alert on state modifications.
* *Network security*: Private endpoints/VPC endpoints where possible, no public internet access in production, firewall rules restricting access.

*Best practices*:

* *Never store backend config with secrets in Git* - use partial config + CLI/env vars.
* *Separate backends per environment* - different buckets for dev/staging/prod.
* *Enable versioning* - recover from mistakes.
* *Regular backups* - automated backup beyond versioning.
* *Monitoring* - alert on state access patterns.
* *Documentation* - document backend setup for team.

Choosing right backend depends on cloud provider, team size, security requirements, and budget - but any remote backend is better than local state for production use.

== What is state locking and why is it important?

State locking prevents concurrent Terraform operations that could corrupt the state file by ensuring only one operation modifies state at a time.

*Why locking is critical*:

* *Prevent corruption* - two simultaneous `terraform apply` commands would race to update state, resulting in corrupted state, lost updates, or broken infrastructure.
* *Ensure consistency* - guarantees state file represents single consistent point in time.
* *Enable collaboration* - allows team members to work safely without coordination overhead.
* *Protect against mistakes* - prevents accidental simultaneous deployments.

*How locking works*:

[,bash]
----
1. terraform apply starts
2. Acquire lock on state
   - If lock exists: wait or fail
   - If no lock: acquire and proceed
3. Perform operations
4. Update state
5. Release lock
----

*Lock acquisition example*:

[,bash]
----
# Terminal 1
$ terraform apply
Acquiring state lock. This may take a few moments...

# Terminal 2 (simultaneous)
$ terraform apply
Acquiring state lock. This may take a few moments...
Error: Error acquiring the state lock

Error message: ConditionalCheckFailedException: The conditional request failed
Lock Info:
  ID:        a1b2c3d4-5678-90ab-cdef-1234567890ab
  Path:      terraform-state-prod/prod.tfstate
  Operation: OperationTypeApply
  Who:       alice@workstation
  Version:   1.5.0
  Created:   2024-01-20 10:30:15 UTC
  Info:

Terraform acquires a state lock to protect the state from being written
by multiple users at the same time. Please resolve the issue above and try
again.
----

*Locking mechanisms by backend*:

*S3 + DynamoDB* (AWS):

[,hcl]
----
terraform {
  backend "s3" {
    bucket         = "terraform-state"
    key            = "terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"  # Locking table
    encrypt        = true
  }
}
----

DynamoDB table structure:

[,bash]
----
# Create locking table
aws dynamodb create-table \
  --table-name terraform-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST

# Lock entry format
{
  "LockID": "bucket-name/path/terraform.tfstate-md5",
  "Info": {
    "ID": "unique-lock-id",
    "Operation": "OperationTypeApply",
    "Who": "user@host",
    "Version": "1.5.0",
    "Created": "2024-01-20T10:30:15Z"
  }
}
----

*Azure Storage* - built-in blob lease locking:

[,hcl]
----
terraform {
  backend "azurerm" {
    resource_group_name  = "tfstate-rg"
    storage_account_name = "tfstate"
    container_name       = "tfstate"
    key                  = "terraform.tfstate"
    # Locking automatic via blob leases
  }
}
----

*GCS* - built-in locking via object metadata:

[,hcl]
----
terraform {
  backend "gcs" {
    bucket  = "tf-state-bucket"
    prefix  = "terraform/state"
    # Locking automatic
  }
}
----

*Terraform Cloud* - built-in locking with UI:

[,hcl]
----
terraform {
  cloud {
    organization = "my-org"
    workspaces {
      name = "production"
    }
  }
}
----

*Force unlock* (use with extreme caution):

[,bash]
----
# If lock stuck (crashed process, etc.)
terraform force-unlock <LOCK_ID>

# Example
terraform force-unlock a1b2c3d4-5678-90ab-cdef-1234567890ab

# Always verify no other operations running!
----

*Stale lock scenarios*:

*Scenario 1: Process crash*:

----
terraform apply (starts)
→ Acquires lock
→ Process crashes (network, laptop dies, etc.)
→ Lock remains in DynamoDB
→ Future operations blocked

Solution: terraform force-unlock
----

*Scenario 2: Network interruption*:

----
terraform apply
→ Acquires lock
→ Network interruption
→ Terraform thinks still running
→ Lock held but no active operation

Solution: Verify no operation running, then force-unlock
----

*Lock security considerations*:

* *Lock table permissions*: Separate from state file permissions, CI/CD needs lock permissions, monitoring lock operations, audit trail of lock/unlock events.
* *Lock timeout*: Some backends support timeout (lock auto-released after period), prevents indefinite locks from crashes, but be careful with timeouts too short.

*Automated lock management*: CI/CD should handle locks automatically, implement retry logic for lock conflicts, alert on frequent lock conflicts (indicates coordination issues), monitor lock duration (abnormally long = problem).

*Example lock monitoring*:

[,python]
----
# CloudWatch alarm for stuck locks
import boto3

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('terraform-locks')

# Check for locks older than 30 minutes
items = table.scan()
for item in items['Items']:
    lock_age = current_time - item['Created']
    if lock_age > 1800:  # 30 minutes
        alert("Stale lock detected", item)
----

*Best practices*:

* *Always enable locking* in production (it's automatic for most backends).
* *Never disable locking* for convenience.
* *Document force-unlock procedures* - when and how to safely use.
* *Monitor lock conflicts* - frequent conflicts indicate process issues.
* *Automated retries* in CI/CD for transient lock conflicts.
* *Lock ownership* - logs should show who acquired lock.
* *Timeout appropriately* - if backend supports, set reasonable timeout.

State locking is essential safeguard preventing state corruption in collaborative environments - without it, team Terraform usage is dangerous and error-prone.

== How do you manage state locking in Terraform?

State locking management involves configuration, monitoring, and troubleshooting to ensure reliable concurrent operation protection.

*1. Configure locking properly*:

*AWS (S3 + DynamoDB)*:

[,hcl]
----
# Step 1: Create DynamoDB table
resource "aws_dynamodb_table" "terraform_locks" {
  name         = "terraform-locks"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }

  tags = {
    Name = "Terraform State Locks"
  }
}

# Step 2: Configure backend
terraform {
  backend "s3" {
    bucket         = "terraform-state-prod"
    key            = "terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-locks"  # Enable locking
    encrypt        = true
  }
}
----

*Azure* (automatic):

[,hcl]
----
terraform {
  backend "azurerm" {
    # Locking via blob leases (automatic)
    resource_group_name  = "tfstate-rg"
    storage_account_name = "tfstate"
    container_name       = "tfstate"
    key                  = "terraform.tfstate"
  }
}
----

*2. Monitor locks*:

*Check current locks (DynamoDB)*:

[,bash]
----
# List all locks
aws dynamodb scan \
  --table-name terraform-locks \
  --projection-expression "LockID,Info"

# Get specific lock
aws dynamodb get-item \
  --table-name terraform-locks \
  --key '{"LockID": {"S": "terraform-state-prod/terraform.tfstate-md5"}}'
----

*CloudWatch monitoring*:

[,bash]
----
# Monitor lock table activity
aws cloudwatch put-metric-alarm \
  --alarm-name terraform-lock-stuck \
  --alarm-description "Alert on locks held >30min" \
  --metric-name ConsumedReadCapacityUnits \
  --namespace AWS/DynamoDB \
  --statistic Sum \
  --period 1800 \
  --evaluation-periods 1 \
  --threshold 10
----

*3. Handle lock conflicts*:

*Normal conflict* (someone else applying):

[,bash]
----
$ terraform apply
Error: Error acquiring the state lock

Lock Info:
  ID:        abc-123
  Operation: OperationTypeApply
  Who:       bob@workstation
  Created:   2024-01-20 15:30:00 UTC

# Action: Wait for other operation to complete, then retry
----

*Stale lock* (process crashed):

[,bash]
----
# 1. Verify no operations actually running
# Check with team, verify process actually dead

# 2. View lock details
terraform force-unlock -help

# 3. Force unlock (carefully!)
terraform force-unlock abc-123

# Output:
# Do you really want to force-unlock?
#   Only 'yes' will be accepted to confirm.
#
# Enter a value: yes
#
# Terraform state has been successfully unlocked!
----

*4. CI/CD lock management*:

*GitLab CI example* with retry logic:

[,yaml]
----
apply:
  script:
    - |
      for i in {1..5}; do
        if terraform apply -auto-approve; then
          echo "Apply successful"
          exit 0
        elif [[ $? -eq 1 ]]; then
          echo "Lock conflict, retrying in 30s..."
          sleep 30
        else
          echo "Apply failed (not lock issue)"
          exit 1
        fi
      done
      echo "Failed after 5 retries"
      exit 1
----

*GitHub Actions example*:

[,yaml]
----
- name: Terraform Apply
  run: |
    retry=0
    max_retries=3
    while [ $retry -lt $max_retries ]; do
      if terraform apply -auto-approve; then
        exit 0
      fi
      if terraform show 2>&1 | grep -q "state lock"; then
        echo "Lock conflict, retrying..."
        retry=$((retry+1))
        sleep 60
      else
        exit 1
      fi
    done
    exit 1
----

*5. Lock troubleshooting procedures*:

*Procedure for force-unlock*:

[,bash]
----
# 1. Identify the lock
terraform apply  # Note the Lock ID from error

# 2. Verify lock is stale
# - Check with team members
# - Verify process not running
# - Check lock creation time

# 3. Document the unlock
echo "$(date): Force unlocking $LOCK_ID. Reason: Process crashed" >> unlock.log

# 4. Force unlock
terraform force-unlock $LOCK_ID

# 5. Verify state integrity
terraform plan  # Should succeed

# 6. Notify team
# Post in team chat about unlock
----

*6. Prevent lock issues*:

*Graceful shutdown handling*:

[,bash]
----
# Shell script wrapper
#!/bin/bash
trap 'echo "Interrupted, Terraform will release lock..."; exit 1' INT TERM

terraform apply "$@"
----

*Timeout configuration* (if backend supports):

[,hcl]
----
terraform {
  backend "consul" {
    address = "consul.example.com"
    path    = "terraform/state"
    lock    = true

    # Auto-release after timeout
    lock_delay = "30s"
  }
}
----

*7. Lock monitoring dashboard*:

*Terraform Cloud* provides built-in UI showing:

* Active locks
* Lock holder
* Lock duration
* Lock history

*Custom monitoring* for S3/DynamoDB:

[,python]
----
import boto3
from datetime import datetime, timedelta

def check_stale_locks():
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('terraform-locks')

    response = table.scan()
    for item in response['Items']:
        lock_time = datetime.fromisoformat(item['Info']['Created'])
        age = datetime.now() - lock_time

        if age > timedelta(minutes=30):
            print(f"ALERT: Stale lock detected")
            print(f"  Lock ID: {item['LockID']}")
            print(f"  Owner: {item['Info']['Who']}")
            print(f"  Age: {age}")
            # Send alert
----

*8. Best practices*:

* Enable locking on all backends that support it
* Never disable locking for convenience
* Document force-unlock procedures clearly
* Implement automated monitoring for stale locks
* Train team on lock troubleshooting
* Use CI/CD with proper retry logic
* Set up alerts for lock conflicts
* Regular audit of lock events
* Graceful shutdown handling in scripts

Effective lock management ensures team can collaborate safely while maintaining state integrity.

== What happens if you manually edit the `terraform.tfstate` file?

Manually editing state file is *extremely dangerous* and should be avoided except in dire emergency recovery situations.

*Potential consequences*:

*1. State corruption*:

* Invalid JSON syntax breaks Terraform completely
* Incorrect resource IDs cause apply failures
* Broken relationships between resources

*2. Resource mismanagement*:

* Terraform loses track of resources (orphaned infrastructure)
* Attempts to recreate existing resources (conflicts)
* Deletes wrong resources
* Duplicate resource creation

*3. Drift between state and reality*:

* State says resource exists but it doesn't (or vice versa)
* Attributes don't match actual infrastructure
* Dependencies incorrect causing wrong operation order

*4. Team conflicts*:

* Others' Terraform operations fail unexpectedly
* State locking doesn't prevent manual edits
* Team loses confidence in automation

*Example disaster scenario*:

[,json]
----
// Manual edit: Changed instance ID
{
  "resources": [{
    "type": "aws_instance",
    "instances": [{
      "attributes": {
        "id": "i-WRONG_ID",  // Manually changed
        "ami": "ami-abc123"
      }
    }]
  }]
}
----

[,bash]
----
# Next terraform apply
$ terraform apply

Error: deleting EC2 Instance (i-WRONG_ID): InvalidInstanceID.NotFound

# Terraform tries to delete non-existent instance
# Real instance (i-CORRECT_ID) becomes orphaned
# Apply fails, state is now corrupted
----

*Safe state manipulation alternatives*:

*Use `terraform state` commands*:

[,bash]
----
# View state
terraform state list
terraform state show aws_instance.web

# Move resource (rename)
terraform state mv aws_instance.old aws_instance.new

# Remove from state (doesn't delete resource)
terraform state rm aws_instance.web

# Replace resource
terraform apply -replace=aws_instance.web

# Import existing resource
terraform import aws_instance.web i-abc123

# Pull state (for inspection only)
terraform state pull > state.json
terraform state pull | jq .

# Push state (from backup)
terraform state push terraform.tfstate.backup
----

*When manual edit might be "necessary"* (last resort):

*Scenario 1: State corruption recovery*:

[,bash]
----
# 1. Backup current state
terraform state pull > broken.tfstate.backup

# 2. Inspect corruption
cat broken.tfstate.backup | jq .

# 3. If minor JSON syntax error, might fix manually
# BETTER: Restore from versioned backup

# 4. Validate fixed state
cat fixed.tfstate | jq . > /dev/null
echo $?  # Should be 0

# 5. Push fixed state
terraform state push fixed.tfstate

# 6. Verify
terraform plan  # Should work now
----

*Scenario 2: Backend migration issue*:

[,bash]
----
# If backend migration failed mid-process
# State might be in inconsistent state
# Manual intervention might be needed

# 1. Get both states
aws s3 cp s3://old-bucket/terraform.tfstate old.tfstate
aws s3 cp s3://new-bucket/terraform.tfstate new.tfstate

# 2. Compare and manually merge if needed
# (This is complex and error-prone!)

# 3. Validate merged state
terraform state push merged.tfstate
terraform plan
----

*Proper recovery procedures*:

*From version control* (if state versioned):

[,bash]
----
# S3 with versioning
aws s3api list-object-versions \
  --bucket terraform-state \
  --prefix terraform.tfstate

# Restore previous version
aws s3api get-object \
  --bucket terraform-state \
  --key terraform.tfstate \
  --version-id <VERSION_ID> \
  terraform.tfstate

terraform state push terraform.tfstate
----

*From backup*:

[,bash]
----
# Restore from backup
cp terraform.tfstate.backup terraform.tfstate

# Or if remote
terraform state push terraform.tfstate.backup

# Verify
terraform plan
----

*Rebuild state from scratch* (last resort):

[,bash]
----
# 1. Remove all resources from state
terraform state list | xargs -n1 terraform state rm

# 2. Import all resources
terraform import aws_instance.web i-abc123
terraform import aws_s3_bucket.data my-bucket-name
# ... for each resource

# 3. Verify
terraform plan  # Should show no changes
----

*Prevention is key*:

* *Never* manually edit state in production
* Always use `terraform state` commands
* Enable state versioning (S3, Azure, GCS)
* Regular automated state backups
* Implement state locking
* Access control on state storage
* Audit logging of state access
* Team training on state management
* Document recovery procedures
* Test recovery procedures regularly

*If you must manually edit* (absolute emergency):

. Backup current state first
. Understand exactly what you're changing
. Validate JSON syntax
. Test in non-production first
. Document what you changed and why
. Verify with `terraform plan` afterward
. Notify team immediately
. Plan to fix underlying issue properly

*Bottom line*: Manual state editing is almost never the right answer - it's a sign something else went wrong. Focus on prevention and using proper Terraform commands for state manipulation.

== What is configuration drift, and how does IaC address it?

Configuration drift occurs when actual infrastructure state diverges from the defined/intended configuration over time due to manual changes, external modifications, or other out-of-band updates.

*Causes of drift*:

*Manual changes*:

* Engineers make emergency fixes directly in cloud console
* Debugging changes left in place
* Hotfixes applied without updating code
* "Quick" changes bypassing automation

*External automation*:

* Other tools modifying same resources
* Auto-scaling changing instance counts
* AWS/Azure making automatic changes (security patches, etc.)
* Monitoring tools modifying configurations

*Partial failures*:

* Deployment partially succeeds then fails
* Rollback incomplete
* Concurrent operations causing conflicts

*Time-based changes*:

* Resources expiring (certificates, temporary credentials)
* DNS TTL causing changes
* Cost optimization tools modifying instances

*Example drift scenario*:

[,hcl]
----
# Terraform configuration
resource "aws_security_group" "web" {
  ingress {
    from_port   = 443
    to_port     = 443
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# Actual state after manual change:
# Engineer added SSH access via console
# Port 22 ingress rule exists but not in Terraform config

# Result: DRIFT
----

*How IaC (Terraform) addresses drift*:

*1. Single source of truth*: Configuration files define desired state, all changes go through IaC, version control tracks all modifications.

*2. Declarative model*: Describe what you want, not how to get there, Terraform reconciles actual state to match desired state.

*3. State tracking*: State file records managed infrastructure, enables comparison between desired vs. actual.

*4. Drift detection*: `terraform plan` shows drift:

[,bash]
----
$ terraform plan

aws_security_group.web: Refreshing state...

Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform since the
last "terraform apply":

# aws_security_group.web has changed
~ resource "aws_security_group" "web" {
      id          = "sg-abc123"
      name        = "web-sg"

    + ingress {
        + from_port   = 22
        + to_port     = 22
        + protocol    = "tcp"
        + cidr_blocks = ["0.0.0.0/0"]
      }
  }

Unless you have made equivalent changes to your configuration, or ignored
the relevant attributes using ignore_changes, the following plan may include
actions to undo or respond to these changes.

Terraform will perform the following actions:

  # aws_security_group.web will be updated in-place
  ~ resource "aws_security_group" "web" {
      - ingress {
          - from_port   = 22
          - to_port     = 22
          - protocol    = "tcp"
          - cidr_blocks = ["0.0.0.0/0"]
        }
    }

Plan: 0 to add, 1 to change, 0 to destroy.
----

*5. Automated remediation*: `terraform apply` removes drift:

[,bash]
----
$ terraform apply
# Removes the manually-added SSH rule
# Returns configuration to desired state
----

*Drift management strategies*:

*Strategy 1: Continuous reconciliation* (recommended):

[,bash]
----
# Scheduled drift detection
*/30 * * * * cd /terraform && terraform plan -detailed-exitcode
# Exit code 2 = changes detected (drift)

# Alert on drift
if [ $? -eq 2 ]; then
  send_alert "Drift detected in production infrastructure"
fi
----

*Strategy 2: Prevent drift at source*:

[,hcl]
----
# Use lifecycle rules to ignore expected drift
resource "aws_instance" "web" {
  ami = "ami-abc123"
  instance_type = "t3.micro"

  tags = {
    Name = "web-server"
  }

  lifecycle {
    ignore_changes = [
      tags["LastModified"],  # Ignore this tag changing
      user_data,  # Ignore user data changes (if updated externally)
    ]
  }
}
----

*Strategy 3: Detect and alert*:

[,python]
----
# Drift detection script
import subprocess
import json

result = subprocess.run(
    ['terraform', 'plan', '-json'],
    capture_output=True
)

plan = json.loads(result.stdout)
if plan['resource_changes']:
    drift_detected = [
        change for change in plan['resource_changes']
        if change['change']['actions'] != ['no-op']
    ]

    if drift_detected:
        send_alert(f"Drift detected: {len(drift_detected)} resources")
----

*Strategy 4: Prevent manual changes*:

* Read-only console access for most users
* All changes through IaC pipeline
* SCPs/Azure Policies preventing manual modification
* Service control policies blocking console actions

*Strategy 5: Import drift into IaC*:

[,bash]
----
# If manual change was legitimate, update IaC
# 1. Make same change in Terraform config
# 2. Verify plan shows no changes
terraform plan  # Should show: No changes

# Or import if resource created manually
terraform import aws_instance.new i-xyz789
----

*Handling different types of drift*:

*Acceptable drift* (ignore):

[,hcl]
----
resource "aws_autoscaling_group" "web" {
  # ASG changes instance count dynamically
  desired_capacity = 3

  lifecycle {
    ignore_changes = [desired_capacity]  # Ignore ASG adjustments
  }
}
----

*Unacceptable drift* (remediate):

[,hcl]
----
# Security group changes should always be reverted
resource "aws_security_group" "db" {
  # No ignore_changes
  # Any drift will be corrected on next apply
}
----

*Tool-caused drift* (coordinate):

[,hcl]
----
# If monitoring tool adds tags, either:
# 1. Configure tool to not modify Terraform resources
# 2. Ignore those specific tags
resource "aws_instance" "web" {
  lifecycle {
    ignore_changes = [tags["monitoring"]]
  }
}
----

*Continuous drift monitoring* (production pattern):

[,yaml]
----
# CI/CD scheduled job
drift-detection:
  schedule:
    - cron: "0 */4 * * *"  # Every 4 hours
  script:
    - terraform init
    - terraform plan -detailed-exitcode -out=drift.tfplan
  artifacts:
    paths:
      - drift.tfplan
  allow_failure:
    exit_codes: 2  # Exit code 2 = drift detected
  after_script:
    - |
      if [ $CI_JOB_STATUS == "failed" ]; then
        # Drift detected
        terraform show -json drift.tfplan > drift.json
        python send_drift_alert.py drift.json
      fi
----

*Benefits of IaC drift management*:

* Maintains security compliance (prevents security holes)
* Ensures consistency across environments
* Provides audit trail of all changes
* Enables automated remediation
* Reduces configuration errors
* Supports disaster recovery

*Best practices*:

* Regular drift detection (hourly/daily)
* Alert on unexpected drift immediately
* Prevent manual changes through IAM/RBAC
* Document acceptable drift patterns
* Automate drift remediation where safe
* Review drift reports in team meetings
* Update IaC to match intentional drift
* Treat persistent drift as security issue

IaC fundamentally changes drift from "inevitable accumulation of technical debt" to "detectable and correctable deviation" - making infrastructure manageable at scale.

== What is drift detection, and why is it important?

Drift detection is the process of identifying differences between your infrastructure's actual state and its intended state as defined in IaC configuration.

*What drift detection reveals*:

*Unauthorized changes*:

* Manual modifications in cloud console
* Changes by other teams/tools
* Security incidents (attacker modifications)
* Accidental modifications

*Configuration degradation*:

* Security controls disabled/weakened
* Compliance violations
* Resource misconfigurations
* Cost optimization changes

*Operational issues*:

* Failed deployments leaving partial changes
* Auto-scaling changes not reflected in code
* Backup/DR resources out of sync

*Why drift detection is critical*:

*1. Security*:

[,hcl]
----
# Intended: S3 bucket with encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "data" {
  bucket = aws_s3_bucket.data.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Drift: Someone disabled encryption manually
# Without drift detection, you wouldn't know!
# Data now vulnerable
----

*2. Compliance*: Drift can violate compliance requirements (PCI-DSS, HIPAA, SOC 2), drift detection provides audit evidence, enables automated compliance reporting.

*3. Reliability*: Undocumented changes cause unexpected behavior, drift can break dependencies, difficult to troubleshoot issues with unknown configuration.

*4. Cost control*: Unexpected resource changes increase costs, drift detection catches cost optimization bypasses.

*Drift detection methods*:

*Method 1: Terraform plan* (basic):

[,bash]
----
# Manual drift check
terraform plan

# Shows:
# - Resources changed outside Terraform
# - What would be modified to fix drift
# - Additions/deletions needed
----

*Method 2: Automated scheduled checks*:

[,bash]
----
#!/bin/bash
# drift-check.sh

cd /terraform/production

terraform init -backend-config=backend.hcl

# -detailed-exitcode:
#   0 = no changes
#   1 = error
#   2 = changes detected (drift)
terraform plan -detailed-exitcode -out=drift.tfplan

EXIT_CODE=$?

if [ $EXIT_CODE -eq 2 ]; then
  echo "DRIFT DETECTED"
  terraform show -json drift.tfplan > drift.json

  # Send alert
  python3 send_drift_alert.py drift.json

  # Create ticket
  create_jira_ticket "Drift detected in production"
fi

exit $EXIT_CODE
----

*Method 3: CI/CD integration*:

[,yaml]
----
# GitLab CI
drift-detection:
  stage: validate
  only:
    - schedules  # Run on schedule
  script:
    - terraform init
    - |
      if ! terraform plan -detailed-exitcode; then
        echo "Drift detected!"
        terraform show > $CI_PROJECT_DIR/drift-report.txt
      fi
  artifacts:
    when: on_failure
    paths:
      - drift-report.txt
  allow_failure: true
----

*Method 4: Terraform Cloud/Enterprise* (built-in):

* Health assessments
* Drift detection UI
* Automated drift notifications
* Scheduled drift checks

*Method 5: Third-party tools*:

*Driftctl*: Specialized drift detection tool

[,bash]
----
driftctl scan --from tfstate://terraform.tfstate

# Output:
# Found 10 resources
#  - 8 managed by Terraform
#  - 2 unmanaged (drift!)
#    - aws_security_group.manual-sg
#    - aws_s3_bucket.forgotten-bucket
----

*CloudQuery*: Asset inventory and drift detection

[,bash]
----
cloudquery sync aws.yml postgres.yml
cloudquery policy run aws_compliance

# Identifies resources not in Terraform state
----

*Comprehensive drift monitoring setup*:

*1. Scheduled drift detection* (every 4 hours):

[,yaml]
----
# .github/workflows/drift.yml
name: Drift Detection

on:
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours

jobs:
  detect-drift:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: Terraform Init
        run: terraform init

      - name: Detect Drift
        id: plan
        run: |
          terraform plan -detailed-exitcode -out=tfplan
        continue-on-error: true

      - name: Parse Drift
        if: steps.plan.outputs.exitcode == '2'
        run: |
          terraform show -json tfplan > drift.json
          python parse_drift.py drift.json > drift-summary.md

      - name: Create Issue
        if: steps.plan.outputs.exitcode == '2'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Drift Detected in Production',
              body: require('fs').readFileSync('drift-summary.md', 'utf8'),
              labels: ['drift', 'security']
            })
----

*2. Drift alert formatting*:

[,python]
----
# parse_drift.py
import json
import sys

with open(sys.argv[1]) as f:
    plan = json.load(f)

print("# Drift Detection Report\n")
print(f"**Time:** {datetime.now()}\n")

for change in plan['resource_changes']:
    if change['change']['actions'] != ['no-op']:
        print(f"## {change['address']}")
        print(f"**Type:** {change['type']}")
        print(f"**Actions:** {change['change']['actions']}\n")

        if 'before' in change['change']:
            print("### Changes:")
            # Format diff
----

*3. Drift dashboard*:

[,sql]
----
-- Store drift detection results
CREATE TABLE drift_detections (
  id SERIAL PRIMARY KEY,
  detected_at TIMESTAMP,
  environment VARCHAR(50),
  resource_count INT,
  drift_count INT,
  details JSONB
);

-- Query drift trends
SELECT
  DATE(detected_at) as date,
  environment,
  AVG(drift_count) as avg_drift
FROM drift_detections
WHERE detected_at > NOW() - INTERVAL '30 days'
GROUP BY DATE(detected_at), environment
ORDER BY date DESC;
----

*Drift remediation workflows*:

*Workflow 1: Automatic remediation* (low-risk environments):

[,bash]
----
#!/bin/bash
if terraform plan -detailed-exitcode; then
  echo "No drift"
else
  echo "Drift detected, auto-remediating"
  terraform apply -auto-approve
  log_remediation "Auto-remediated drift in dev environment"
fi
----

*Workflow 2: Alert and manual review* (production):

[,bash]
----
if ! terraform plan -detailed-exitcode; then
  # Create incident
  create_pagerduty_incident "Production drift detected"

  # Require manual review and approval
  # Team reviews drift, decides to:
  #   1. Apply (revert drift)
  #   2. Update IaC to match drift
  #   3. Investigate as security incident
fi
----

*Drift detection best practices*:

* Run drift detection frequently (hourly in production)
* Alert immediately on unexpected drift
* Categorize drift (security, compliance, operational)
* Different remediation strategies per category
* Document acceptable drift patterns
* Treat security drift as potential incident
* Regular drift review in team meetings
* Metrics on drift frequency and resolution time
* Test drift detection and remediation procedures
* Combine with compliance scanning

*Metrics to track*:

* Time to detect drift (should be minutes/hours, not days)
* Drift frequency (trending up = process problem)
* Time to remediate drift
* Percentage of auto-remediated vs. manual
* Drift by resource type (which drift most?)
* Drift by team/environment

Effective drift detection transforms infrastructure management from reactive (finding problems after failures) to proactive (preventing problems before impact) - essential for security, compliance, and reliability at scale.

== How do you perform drift detection in Terraform?

Drift detection in Terraform can be performed through several methods, from manual commands to fully automated continuous monitoring.

*Method 1: Manual drift detection* (terraform plan):

[,bash]
----
# Basic drift check
terraform plan

# The output will show:
# 1. Objects changed outside Terraform (drift)
# 2. Actions Terraform would take to fix drift
----

*Example output*:

[,console]
----
$ terraform plan

aws_security_group.web: Refreshing state... [id=sg-abc123]

Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform since the
last "terraform apply":

  # aws_security_group.web has changed
  ~ resource "aws_security_group" "web" {
        id          = "sg-abc123"
        name        = "web-sg"

      + ingress {
          + cidr_blocks      = [
              + "0.0.0.0/0",
            ]
          + from_port        = 22
          + protocol         = "tcp"
          + to_port          = 22
        }
    }

Unless you have made equivalent changes to your configuration, or ignored the
relevant attributes using ignore_changes, the following plan may include
actions to undo or respond to these changes.

Terraform will perform the following actions:

  # aws_security_group.web will be updated in-place
  ~ resource "aws_security_group" "web" {
        id          = "sg-abc123"

      - ingress {
          - cidr_blocks      = [
              - "0.0.0.0/0",
            ]
          - from_port        = 22
          - protocol         = "tcp"
          - to_port          = 22
        }
    }

Plan: 0 to add, 1 to change, 0 to destroy.
----

*Method 2: Detailed exit code for automation*:

[,bash]
----
terraform plan -detailed-exitcode

# Exit codes:
#   0 = Succeeded, no diff
#   1 = Error
#   2 = Succeeded, there is a diff (DRIFT DETECTED)

# Use in scripts:
if ! terraform plan -detailed-exitcode; then
  echo "Drift detected or error occurred"
  exit 1
fi
----

*Method 3: JSON output for parsing*:

[,bash]
----
# Generate plan with drift
terraform plan -out=tfplan

# Convert to JSON
terraform show -json tfplan > drift.json

# Parse JSON
cat drift.json | jq '.resource_changes[] | select(.change.actions != ["no-op"])'
----

*Example drift parsing script*:

[,python]
----
#!/usr/bin/env python3
import json
import sys

with open('drift.json') as f:
    plan = json.load(f)

drift_resources = []

for change in plan.get('resource_changes', []):
    actions = change['change']['actions']

    # Skip no-op (no drift)
    if actions == ['no-op']:
        continue

    drift_resources.append({
        'address': change['address'],
        'type': change['type'],
        'actions': actions,
        'before': change['change'].get('before'),
        'after': change['change'].get('after')
    })

if drift_resources:
    print(f"🚨 Drift detected in {len(drift_resources)} resources:")
    for resource in drift_resources:
        print(f"\n  Resource: {resource['address']}")
        print(f"  Actions: {', '.join(resource['actions'])}")
else:
    print("✅ No drift detected")

sys.exit(2 if drift_resources else 0)
----

*Method 4: Automated scheduled drift detection*:

*Cron-based*:

[,bash]
----
# crontab
0 */4 * * * /usr/local/bin/drift-check.sh

# drift-check.sh
#!/bin/bash
set -e

cd /terraform/production

export AWS_PROFILE=production

terraform init -backend-config=backend.hcl

if ! terraform plan -detailed-exitcode -out=drift.tfplan 2>&1 | tee drift.log; then
  EXIT_CODE=${PIPESTATUS[0]}

  if [ $EXIT_CODE -eq 2 ]; then
    # Drift detected
    terraform show -json drift.tfplan > drift.json

    # Send Slack notification
    curl -X POST -H 'Content-type: application/json' \
      --data "{\"text\":\"⚠️ Drift detected in production infrastructure\"}" \
      $SLACK_WEBHOOK_URL

    # Email security team
    mail -s "Production Drift Detected" security@company.com < drift.log

    # Create Jira ticket
    python3 /scripts/create_jira_drift_ticket.py drift.json
  fi
fi
----

*Method 5: CI/CD pipeline drift detection*:

*GitHub Actions*:

[,yaml]
----
name: Drift Detection

on:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours
  workflow_dispatch:  # Manual trigger

jobs:
  drift-detection:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Terraform Init
        run: terraform init

      - name: Drift Detection
        id: drift
        run: |
          terraform plan -detailed-exitcode -out=tfplan || EXIT_CODE=$?
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT

          if [ "$EXIT_CODE" == "2" ]; then
            terraform show -json tfplan > drift.json
            echo "drift_detected=true" >> $GITHUB_OUTPUT
          fi

      - name: Parse Drift
        if: steps.drift.outputs.drift_detected == 'true'
        run: |
          python3 .github/scripts/parse_drift.py drift.json > drift-report.md

      - name: Create Issue
        if: steps.drift.outputs.drift_detected == 'true'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const drift = fs.readFileSync('drift-report.md', 'utf8');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Drift Detected - ${new Date().toISOString()}`,
              body: drift,
              labels: ['drift', 'infrastructure', 'security']
            });

      - name: Slack Notification
        if: steps.drift.outputs.drift_detected == 'true'
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "🚨 Infrastructure drift detected in production",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Drift Detection Alert*\n\nDrift detected in production infrastructure. Review required."
                  }
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Details"
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
----

*GitLab CI*:

[,yaml]
----
drift-detection:
  stage: validate
  only:
    - schedules
  script:
    - terraform init
    - |
      if ! terraform plan -detailed-exitcode -out=tfplan; then
        EXIT_CODE=$?
        if [ $EXIT_CODE -eq 2 ]; then
          echo "Drift detected"
          terraform show -json tfplan > drift.json
          python3 scripts/alert_drift.py drift.json
        fi
      fi
  artifacts:
    when: on_failure
    paths:
      - tfplan
      - drift.json
    expire_in: 7 days
  allow_failure: true
----

*Method 6: Terraform Cloud Drift Detection*:

Terraform Cloud/Enterprise has built-in drift detection:

[,hcl]
----
# Configure workspace for drift detection
terraform {
  cloud {
    organization = "my-org"

    workspaces {
      name = "production"
    }
  }
}
----

In Terraform Cloud UI:

. Navigate to workspace settings
. Enable "Health Assessments"
. Configure drift detection schedule
. Set up notifications (Slack, email, webhooks)

*Method 7: Third-party drift detection tools*:

*Driftctl*:

[,bash]
----
# Install
brew install driftctl

# Scan for drift
driftctl scan

# Compare Terraform state with actual cloud resources
driftctl scan --from tfstate://terraform.tfstate --to aws+tf

# Output unmanaged resources
driftctl scan --output json://drift-report.json

# Example output:
# Found 25 resource(s)
#  - 100% coverage
#  - 23 managed by Terraform
#  - 2 not managed by IaC:
#     - aws_security_group.manual-sg-123
#     - aws_s3_bucket.forgotten-bucket
----

*Comprehensive drift detection setup* (production-ready):

[,bash]
----
#!/bin/bash
# /usr/local/bin/comprehensive-drift-check.sh

set -euo pipefail

ENVIRONMENT=${1:-production}
TERRAFORM_DIR="/terraform/${ENVIRONMENT}"
ALERT_THRESHOLD=5  # Alert if >5 resources drifted

cd "$TERRAFORM_DIR"

# Initialize
terraform init -backend-config="backend-${ENVIRONMENT}.hcl"

# Run plan
terraform plan -detailed-exitcode -out=drift.tfplan 2>&1 | tee drift.log
EXIT_CODE=${PIPESTATUS[0]}

if [ $EXIT_CODE -eq 0 ]; then
  echo "✅ No drift detected"
  exit 0
elif [ $EXIT_CODE -eq 1 ]; then
  echo "❌ Terraform plan failed"
  cat drift.log | mail -s "Terraform Plan Error - ${ENVIRONMENT}" ops@company.com
  exit 1
elif [ $EXIT_CODE -eq 2 ]; then
  echo "⚠️  Drift detected"

  # Convert to JSON
  terraform show -json drift.tfplan > drift.json

  # Count drifted resources
  DRIFT_COUNT=$(cat drift.json | jq '[.resource_changes[] | select(.change.actions != ["no-op"])] | length')

  echo "Drifted resources: $DRIFT_COUNT"

  # Parse drift details
  python3 /scripts/parse_drift.py drift.json > drift-report.md

  # Alert based on severity
  if [ $DRIFT_COUNT -gt $ALERT_THRESHOLD ]; then
    # High drift - page on-call
    curl -X POST "https://events.pagerduty.com/v2/enqueue" \
      -H "Content-Type: application/json" \
      -d "{
        \"routing_key\": \"$PAGERDUTY_KEY\",
        \"event_action\": \"trigger\",
        \"payload\": {
          \"summary\": \"High drift detected: $DRIFT_COUNT resources in ${ENVIRONMENT}\",
          \"severity\": \"error\",
          \"source\": \"terraform-drift-detection\"
        }
      }"
  else
    # Low drift - Slack notification
    curl -X POST "$SLACK_WEBHOOK" \
      -H "Content-Type: application/json" \
      -d "{\"text\": \"Drift detected: $DRIFT_COUNT resources in ${ENVIRONMENT}\"}"
  fi

  # Create Jira ticket
  python3 /scripts/create_jira.py \
    --summary "Drift detected in ${ENVIRONMENT}" \
    --description "$(cat drift-report.md)"

  # Store in database for trending
  python3 /scripts/store_drift_metrics.py \
    --environment "$ENVIRONMENT" \
    --drift_count "$DRIFT_COUNT" \
    --details drift.json

  exit 2
fi
----

*Best practices for drift detection*:

* Run frequently (hourly in critical environments)
* Different schedules for different environments
* Alert appropriately (PagerDuty for prod, Slack for dev)
* Track drift metrics over time
* Review drift patterns in team retrospectives
* Automate remediation where safe
* Document acceptable drift
* Include drift detection in incident response procedures
* Test drift detection regularly
* Monitor drift detection job failures

Effective drift detection requires automation, appropriate alerting, and clear remediation procedures - it's a continuous process, not a one-time check.
